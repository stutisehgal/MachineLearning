{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset: (60000, 785)\n",
      "Shape of testing dataset: (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "#importing dataset\n",
    "dataset_train=pd.read_csv('mnist_train.csv') # has 10 classes-- 0 to 9 digits and labels\n",
    "dataset_test=pd.read_csv('mnist_test.csv')\n",
    "print(\"Shape of training dataset:\",dataset_train.shape)\n",
    "print(\"Shape of testing dataset:\",dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of training dataset:               label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
      "count  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
      "mean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
      "count  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \n",
      "mean       0.0      0.0      0.0  ...      0.200433      0.088867   \n",
      "std        0.0      0.0      0.0  ...      6.042472      3.956189   \n",
      "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
      "\n",
      "              28x21         28x22         28x23       28x24    28x25    28x26  \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \n",
      "mean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \n",
      "std        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \n",
      "min        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
      "25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
      "50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
      "75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
      "max      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n",
      "\n",
      "         28x27    28x28  \n",
      "count  60000.0  60000.0  \n",
      "mean       0.0      0.0  \n",
      "std        0.0      0.0  \n",
      "min        0.0      0.0  \n",
      "25%        0.0      0.0  \n",
      "50%        0.0      0.0  \n",
      "75%        0.0      0.0  \n",
      "max        0.0      0.0  \n",
      "\n",
      "[8 rows x 785 columns]\n",
      "Description of test dataset:               label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
      "count  10000.000000  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0   \n",
      "mean       4.443400      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        2.895865      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
      "count  10000.0  10000.0  10000.0  ...  10000.000000  10000.000000   \n",
      "mean       0.0      0.0      0.0  ...      0.179300      0.163600   \n",
      "std        0.0      0.0      0.0  ...      5.674149      5.736072   \n",
      "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "max        0.0      0.0      0.0  ...    253.000000    253.000000   \n",
      "\n",
      "              28x21       28x22    28x23    28x24    28x25    28x26    28x27  \\\n",
      "count  10000.000000  10000.0000  10000.0  10000.0  10000.0  10000.0  10000.0   \n",
      "mean       0.052600      0.0006      0.0      0.0      0.0      0.0      0.0   \n",
      "std        2.420004      0.0600      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n",
      "max      156.000000      6.0000      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "         28x28  \n",
      "count  10000.0  \n",
      "mean       0.0  \n",
      "std        0.0  \n",
      "min        0.0  \n",
      "25%        0.0  \n",
      "50%        0.0  \n",
      "75%        0.0  \n",
      "max        0.0  \n",
      "\n",
      "[8 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Description of training dataset:\",dataset_train.describe())\n",
    "print(\"Description of test dataset:\",dataset_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in training dataset: label    0\n",
      "1x1      0\n",
      "1x2      0\n",
      "1x3      0\n",
      "1x4      0\n",
      "1x5      0\n",
      "1x6      0\n",
      "1x7      0\n",
      "1x8      0\n",
      "1x9      0\n",
      "dtype: int64\n",
      "Null values in test dataset: label    0\n",
      "1x1      0\n",
      "1x2      0\n",
      "1x3      0\n",
      "1x4      0\n",
      "1x5      0\n",
      "1x6      0\n",
      "1x7      0\n",
      "1x8      0\n",
      "1x9      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for null and np.nan values\n",
    "print(\"Null values in training dataset:\",dataset_train.isnull().sum().head(10))\n",
    "print(\"Null values in test dataset:\",dataset_test.isnull().sum().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "order = list(np.sort(dataset_train['label'].unique()))\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6742\n",
       "7    6265\n",
       "3    6131\n",
       "2    5958\n",
       "9    5949\n",
       "0    5923\n",
       "6    5918\n",
       "8    5851\n",
       "4    5842\n",
       "5    5421\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualizing the number of class ie digits and counts in the datasets\n",
    "plt.plot(figure = (16,10))\n",
    "g = sns.countplot( dataset_train[\"label\"], palette = 'winter')\n",
    "plt.title('Number of digit classes')\n",
    "dataset_train.label.value_counts() \n",
    "#count the number of classes ie digits from 0-9 to idrentify any biasing towards a class by occurence/frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'four = dataset_train.iloc[3, 1:] #1st column is the label column at index 0\\nprint(four.shape)\\nfour = four.values.reshape(28,28)\\n# opening image in bigger size than allowed on canvas by default on notebook\\nfig=plt.figure(figsize=(14,12)) # by adjusting fgsize dimensions, open image in bigger size\\nax=fig.add_subplot(111) # by adjusting size of width,height and color channel\\nax.imshow(four)\\nplt.imshow(four, cmap=\\'gray\\') # to remove color channel from input image\\nplt.title(\"Digit 4\")\\nfour'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting some samples as well as converting into matrix\n",
    "'''four = dataset_train.iloc[3, 1:] #1st column is the label column at index 0\n",
    "print(four.shape)\n",
    "four = four.values.reshape(28,28)\n",
    "# opening image in bigger size than allowed on canvas by default on notebook\n",
    "fig=plt.figure(figsize=(14,12)) # by adjusting fgsize dimensions, open image in bigger size\n",
    "ax=fig.add_subplot(111) # by adjusting size of width,height and color channel\n",
    "ax.imshow(four)\n",
    "plt.imshow(four, cmap='gray') # to remove color channel from input image\n",
    "plt.title(\"Digit 4\")\n",
    "four'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x1      0.0\n",
       "1x2      0.0\n",
       "1x3      0.0\n",
       "1x4      0.0\n",
       "1x5      0.0\n",
       "        ... \n",
       "28x24    0.0\n",
       "28x25    0.0\n",
       "28x26    0.0\n",
       "28x27    0.0\n",
       "28x28    0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average feature values\n",
    "round(dataset_train.drop('label', axis=1).mean(), 2) \n",
    "#drop label column of dataset while calculating mean of all other columns rounded off upto 2nd decimal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# Separating the X and Y variable\n",
    "\n",
    "y_dataset_train = dataset_train['label']\n",
    "# Dropping the variable 'label' from X variable \n",
    "X_dataset_train = dataset_train.drop(columns = 'label') #drop  labels column at index 0\n",
    "# Printing the size of data \n",
    "print(X_dataset_train.shape)\n",
    "print(y_dataset_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 784)\n",
      "Test dataset: (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Normalization-- all values lie between 0 and 255 so by dividing all values by 255, they will lie between 0 and 1\n",
    "X_dataset_train = X_dataset_train/255.0\n",
    "dataset_test = dataset_test/255.0\n",
    "print(\"X:\",X_dataset_train.shape)\n",
    "print(\"Test dataset:\",dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#feature scaling independent feature variable X\n",
    "mm_X = MinMaxScaler()\n",
    "X_dataset_train = mm_X.fit_transform(X_dataset_train)\n",
    "\n",
    "#splitting dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset_train, y_dataset_train, test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SVM model to training dataset\n",
    "from sklearn.svm import SVC\n",
    "classifier=SVC(kernel='rbf') #hyperparameter tuning c and gamma values\n",
    "#linear kernel only gives 91.8% accuracy\n",
    "#polynomial kernel with degree=3 gives 86% accuracy\n",
    "#sigmoid kernel gives 91.1% accuracy\n",
    "#rbf kernel gives 97.816% accuracy so i used rbf kernel\n",
    "model = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output values: [3 6 6 ... 5 1 6]\n"
     ]
    }
   ],
   "source": [
    "#Predicting results of training dataset\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(\"Predicted output values:\",y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 6, ..., 5, 1, 6], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.81666666666666 \n",
      "\n",
      "[[1195    0    0    0    0    2    6    0    2    0]\n",
      " [   0 1372    2    1    2    0    1    0    0    1]\n",
      " [   0    1 1142    5    4    1    1    6    5    1]\n",
      " [   0    0    9 1169    0   14    0    4   12    0]\n",
      " [   0    2    2    0 1132    0    3    4    1    9]\n",
      " [   5    0    3   12    4 1035    8    0    5    3]\n",
      " [   2    2    3    0    3    5 1173    0    2    0]\n",
      " [   0    2    8    1    5    0    1 1199    1   11]\n",
      " [   1    5    5    2    2    8    4    0 1161    3]\n",
      " [   1    0    0    6   17    5    0   10    6 1160]]\n",
      "Mean squared error: 0.3388333333333333\n",
      "Mean absolute error: 0.0755\n",
      "Accuracy: 95.98114200470734\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy=metrics.accuracy_score(y_true=y_test, y_pred=y_pred)*100\n",
    "print(\"Accuracy:\", accuracy, \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "# CALCULTING ERROR AND ACCURACY OF PREDICTION MODEL\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean squared error:',mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean absolute error:',mae)\n",
    "r_score = r2_score(y_test, y_pred)\n",
    "print('Accuracy:',r_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model,\"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
